:content-type-negotiation: https://docs.spring.io/spring-cloud-stream/docs/current/reference/html/spring-cloud-stream.html#content-type-management
== Spring Cloud Stream Support

Spring Cloud Stream is a framework for building highly scalable event-driven microservices connected with shared messaging systems.

The framework provides a flexible programming model built on already established and familiar Spring idioms and best practices, including support for persistent pub/sub semantics, consumer groups, and stateful partitions.

Current binder implementations include:

* spring-cloud-azure-stream-binder-eventhubs
* spring-cloud-azure-stream-binder-servicebus

=== Spring Cloud Stream Binder for Azure Event Hubs

==== Key concepts
The Spring Cloud Stream Binder for Azure Event Hubs provides the binding implementation for the Spring Cloud Stream framework.
This implementation uses Spring Integration Event Hubs Channel Adapters at its foundation. From design's perspective,
Event Hubs is similar as Kafka. Also, Event Hubs could be accessed via Kafka API. If your project has tight dependency
on Kafka API, you can try link:https://github.com/Azure-Samples/azure-spring-boot-samples/tree/spring-cloud-azure_{project-version}/eventhubs/spring-cloud-azure-starter/spring-cloud-azure-sample-eventhubs-kafka[Events Hub with Kafka API Sample]

===== Consumer Group

Event Hubs provides similar support of consumer group as Apache Kafka, but with slight different logic. While Kafka
stores all committed offsets in the broker, you have to store offsets of Event Hubs messages
being processed manually. Event Hubs SDK provide the function to store such offsets inside Azure Storage Account. So
that's why you have to fill `spring.cloud.eventhubs.processor.checkpoint-store.*`.

===== Partitioning Support

Event Hubs provides a similar concept of physical partition as Kafka. But unlike Kafka's auto re-balancing between consumers and partitions, Event Hubs provides a kind of preemptive mode. The storage account acts as a lease to determine which partition is owned by which consumer. When a new consumer starts, it will try to steal some partitions
from most heavy-loaded consumers to achieve the workload balancing.

To specify the load balancing strategy, properties of `spring.cloud.stream.eventhubs.bindings.<binding-name>.consumer.load-balancing.*` are provided. See <<eventhubs-consumer-properties, the consumer properties>> for more details.

===== Batch Consumer Support
Spring Cloud Azure Stream Event Hubs binder supports link:https://docs.spring.io/spring-cloud-stream/docs/current/reference/html/spring-cloud-stream.html#_batch_consumers[Spring Cloud Stream Batch Consumer feature].

To work with the batch-consumer mode, the property of `spring.cloud.stream.bindings.<binding-name>.consumer.batch-mode` should be set as `true`. When enabled, an **org.springframework.messaging.Message** of which the payload is a list of batched events will be received and passed to the consumer function. Each message header is also converted as a list, of which the content is the associated header value parsed from each event. For the communal headers of partition id, checkpointer and last enqueued properties, they are presented as a single value for the entire batch of events shares the same one. See <<scs-eh-headers, Event Hubs Message Headers>> for more details.

NOTE: The checkpoint header only exists when **MANUAL** checkpoint mode is used.

Checkpointing of batch consumer supports two modes: `BATCH` and `MANUAL`. `BATCH` mode is an auto checkpointing mode to checkpoint the entire batch of events together once they are received by the binder. `MANUAL` mode is to checkpoint the events by users. When used, the
**com.azure.spring.messaging.checkpoint.Checkpointer** will be passes into the message header, and users could use it to do checkpointing.

The batch size can be specified by properties of `max-size` and `max-wait-time` with prefix as `spring.cloud.stream.eventhubs.bindings.<binding-name>.consumer.batch.`, where `max-size` is a necessary property while `max-wait-time` is optional. See <<eventhubs-consumer-properties, the consumer properties>> for more details.

==== Dependency Setup

[source,xml]
----
<dependency>
	<groupId>com.azure.spring</groupId>
	<artifactId>spring-cloud-azure-stream-binder-eventhubs</artifactId>
</dependency>
----
Alternatively, you can also use the Spring Cloud Azure Stream Event Hubs Starter, as shown in the following example for Maven:

[source,xml]
----
<dependency>
	<groupId>com.azure.spring</groupId>
	<artifactId>spring-cloud-azure-starter-stream-eventhubs</artifactId>
</dependency>
----

==== Configuration

The binder provides the following 3 parts of configuration options:

[#eventhubs-connection-configration]
===== Connection Configuration Properties
These properties are exposed via `com.azure.spring.cloud.autoconfigure.implementation.eventhubs.properties.AzureEventHubsProperties`.

NOTE: If you choose to use a security principal to authenticate and authorize with Azure Active Directory for accessing an Azure resource, please refer to link:index.html#authorize-access-with-azure-active-directory[Authorize access with Azure AD] to make sure the security principal has been granted the sufficient permission to access the Azure resource.

.Connection configurable properties of spring-cloud-azure-stream-binder-eventhubs
[cols="<,<,<", options="header"]
|===
|Property | Type |Description

|*spring.cloud.azure.eventhubs*.enabled
| boolean
| Whether an Azure Event Hubs is enabled.

|*spring.cloud.azure.eventhubs*.connection-string
| String
| Event Hubs Namespace connection string value.

|*spring.cloud.azure.eventhubs*.namespace
| String
| Event Hubs Namespace value, which is the prefix of the FQDN. A FQDN should be composed of <NamespaceName>.<DomainName>


|*spring.cloud.azure.eventhubs*.domain-name
| String
| Domain name of an Azure Event Hubs Namespace value.

|*spring.cloud.azure.eventhubs*.custom-endpoint-address
| String
| Custom Endpoint address.

|===

TIP: Common Azure Service SDK configuration options are configurable for the Spring Cloud Azure Stream Event Hubs binder as well. The supported configuration options are introduced in link:configuration.html[the Configuration page], and could be configured with either the unified prefix `spring.cloud.azure.` or the prefix of `spring.cloud.azure.eventhubs.`.

===== Checkpoint Configuration Properties
These properties are exposed via `com.azure.spring.cloud.autoconfigure.implementation.eventhubs.properties.AzureEventHubsProperties.Processor#checkpointStore`
for the configuration of `BlobCheckpointStore`, which is the default implementation of `CheckpointStore` to use Storage Blobs for persisting partition ownership and checkpoint information.

NOTE: From version 4.0.0, when the property of **spring.cloud.azure.eventhubs.processor.checkpoint-store.create-container-if-not-exists** is not enabled manually, no Storage container will be created automatically with the name from **spring.cloud.stream.bindings.<binding-name>.destination**.

.Checkpointing configurable properties of spring-cloud-azure-stream-binder-eventhubs
[cols="<,<,<", options="header"]
|===
|Property | Type |Description

|*spring.cloud.azure.eventhubs.processor.checkpoint-store*.create-container-if-not-exists
|Boolean
|If allowed creating containers if not exists.

|*spring.cloud.azure.eventhubs.processor.checkpoint-store*.account-name
| String
| Name for the storage account.

|*spring.cloud.azure.eventhubs.processor.checkpoint-store*.account-key
| String
| Storage account access key.

|*spring.cloud.azure.eventhubs.processor.checkpoint-store*.container-name
| String
| Storage container name.
|===

TIP: Common Azure Service SDK configuration options are configurable for Storage Blob checkpoint store as well. The supported configuration options are introduced in link:configuration.html[the Configuration page], and could be configured with either the unified prefix `spring.cloud.azure.` or the prefix of `spring.cloud.azure.eventhubs.processor.checkpoint-store`.

NOTE: The default maximum connection pool size of the Storage Blob client is changed from `500` in version 3.x to `16` now, and the pending acquire queue size which is double of pool size is then `32` now. To override them, please set the property `spring.cloud.azure.eventhubs.processor.checkpoint-store.client.maximum-connection-pool-size`.

===== Azure Event Hubs Binding Configuration Properties
Below options are divided into four sections: Consumer Properties, Advanced Consumer
Configurations, Producer Properties and Advanced Producer Configurations.

[#eventhubs-consumer-properties]
====== Consumer Properties

.Consumer configurable properties of spring-cloud-azure-stream-binder-eventhubs
[cols="<,<,<", options="header"]
|===
|Property | Type |Description

|*spring.cloud.stream.eventhubs.bindings.<binding-name>.consumer*.checkpoint.mode
|CheckpointMode
| Checkpoint mode used when consumer decide how to checkpoint message

|*spring.cloud.stream.eventhubs.bindings.<binding-name>.consumer*.checkpoint.count
| Integer
|Decides the amount of message for each partition to do one checkpoint. Will take effect only when `PARTITION_COUNT` checkpoint mode is used.

|*spring.cloud.stream.eventhubs.bindings.<binding-name>.consumer*.checkpoint.interval
| Duration
|Decides the time interval to do one checkpoint. Will take effect only when `TIME` checkpoint mode is used.

|*spring.cloud.stream.eventhubs.bindings.<binding-name>.consumer*.batch.max-size
| Integer
| The maximum number of events in a batch. Required for the batch-consumer mode.

|*spring.cloud.stream.eventhubs.bindings.<binding-name>.consumer*.batch.max-wait-time
| Duration
| The maximum time duration for batch consuming. Will take effect only when the batch-consumer mode is enabled and is optional.

|*spring.cloud.stream.eventhubs.bindings.<binding-name>.consumer*.load-balancing.update-interval
| Duration
| The interval time duration for updating.

|*spring.cloud.stream.eventhubs.bindings.<binding-name>.consumer*.load-balancing.strategy
|LoadBalancingStrategy
|The load balancing strategy.

|*spring.cloud.stream.eventhubs.bindings.<binding-name>.consumer*.load-balancing.partition-ownership-expiration-interval
|Duration
|The time duration after which the ownership of partition expires.

|*spring.cloud.stream.eventhubs.bindings.<binding-name>.consumer*.track-last-enqueued-event-properties
|Boolean
|Whether the event processor should request information on the last enqueued event on its associated partition, and track that information as events are received.

|*spring.cloud.stream.eventhubs.bindings.<binding-name>.consumer*.prefetch-count
|Integer
|The count used by the consumer to control the number of events the Event Hub consumer will actively receive and queue locally.

|*spring.cloud.stream.eventhubs.bindings.<binding-name>.consumer*.initial-partition-event-position
|Map with the key as the partition id, and values of `StartPositionProperties`
|The map containing the event position to use for each partition if a checkpoint for the partition does not exist in checkpoint store. This map is keyed off of the partition id.
|===

NOTE: The `initial-partition-event-position` configuration accepts a `map` to specify the initial position for each event hub. Thus, its key is the partition id, and the value is of `com.azure.spring.cloud.service.eventhubs.properties.StartPositionProperties` which includes properties of offset, sequence number, enqueued date time and whether inclusive. For example, you can set it as

[source,yaml]
----
spring:
  cloud:
    stream:
      eventhubs:
        bindings:
          <binding-name>:
            consumer:
              initial-partition-event-position:
                0:
                  offset: earliest
                1:
                  sequence-number: 100
                2:
                  enqueued-date-time: 2022-01-12T13:32:47.650005Z
                4:
                  inclusive: false
----

====== Advanced Consumer Configuration
The above <<eventhubs-connection-configration, connection>>, <<Checkpoint Configuration Properties, checkpoint>> and <<Configuration.adoc#configuration, common Azure SDK client>> configuration are supported to be customized for each binder consumer, which can be configured with the prefix `spring.cloud.stream.eventhubs.bindings.<binding-name>.consumer.`.

====== Producer Properties

.Producer configurable properties of spring-cloud-azure-stream-binder-eventhubs
[cols="<,<,<", options="header"]
|===
|Property | Type |Description

|*spring.cloud.stream.eventhubs.bindings.<binding-name>.producer*.sync
| boolean
|The switch flag for sync of producer. If true, the producer will wait for a response after a send operation.

|*spring.cloud.stream.eventhubs.bindings.<binding-name>.producer*.send-timeout
| long
|The amount of time to wait for a response after a send operation. Will take effect only when a sync producer is enabled.
|===

====== Advanced Producer Configuration
The above <<eventhubs-connection-configration, connection>> and <<Configuration.adoc#configuration, common Azure SDK client>> configuration are supported to be customized for each binder producer, which can be configured with the prefix `spring.cloud.stream.eventhubs.bindings.<binding-name>.producer.`.

==== Basic Usage
===== Sending and receiving messages from/to Event Hubs
Step 1. Fill the configuration options with credential information.

- For credentials as connection string, configure below properties in application.yml:

[source,yaml]
----
spring:
  cloud:
    azure:
      eventhubs:
        connection-string: ${EVENTHUB_NAMESPACE_CONNECTION_STRING}
        processor:
          checkpoint-store:
            container-name: ${CHECKPOINT_CONTAINER}
            account-name: ${CHECKPOINT_STORAGE_ACCOUNT}
            account-key: ${CHECKPOINT_ACCESS_KEY}
    stream:
      function:
        definition: consume;supply
      bindings:
        consume-in-0:
          destination: ${EVENTHUB_NAME}
          group: ${CONSUMER_GROUP}
        supply-out-0:
          destination: ${THE_SAME_EVENTHUB_NAME_AS_ABOVE}
      eventhubs:
        bindings:
          consume-in-0:
            consumer:
              checkpoint:
                mode: MANUAL
----

- For credentials as service principal, configure below properties in application.yml:

[source, yaml]
----
spring:
  cloud:
    azure:
      credential:
        client-id: ${SERVICE_PRINCIPAL_ID}
        client-secret: ${SERVICE_PRINCIPAL_SECRET}
      profile:
        tenant-id: ${TENANT_ID}
      eventhubs:
        namespace: ${EVENTHUB_NAMESPACE}
        processor:
          checkpoint-store:
            container-name: ${CONTAINER_NAME}
            account-name: ${ACCOUNT_NAME}
    stream:
      function:
        definition: consume;supply
      bindings:
        consume-in-0:
          destination: ${EVENTHUB_NAME}
          group: ${CONSUMER_GROUP}
        supply-out-0:
          destination: ${THE_SAME_EVENTHUB_NAME_AS_ABOVE}
      eventhubs:
        bindings:
          consume-in-0:
            consumer:
              checkpoint:
                mode: MANUAL
----

- For credentials as MSI, configure below properties in application.yml:

[source, yaml]
----
spring:
  cloud:
    azure:
      credential:
        managed-identity-client-id: ${AZURE_MANAGED_IDENTITY_CLIENT_ID}
      eventhubs:
        namespace: ${EVENTHUB_NAMESPACE}
        processor:
          checkpoint-store:
            container-name: ${CONTAINER_NAME}
            account-name: ${ACCOUNT_NAME}
    stream:
      function:
        definition: consume;supply
      bindings:
        consume-in-0:
          destination: ${EVENTHUB_NAME}
          group: ${CONSUMER_GROUP}
        supply-out-0:
          destination: ${THE_SAME_EVENTHUB_NAME_AS_ABOVE}

      eventhubs:
        bindings:
          consume-in-0:
            consumer:
              checkpoint:
                mode: MANUAL
----



Step2. Define supplier and consumer.
[source,java]
----
@Bean
public Consumer<Message<String>> consume() {
    return message -> {
        Checkpointer checkpointer = (Checkpointer) message.getHeaders().get(CHECKPOINTER);
        LOGGER.info("New message received: '{}', partition key: {}, sequence number: {}, offset: {}, enqueued time: {}",
                message.getPayload(),
                message.getHeaders().get(EventHubsHeaders.PARTITION_KEY),
                message.getHeaders().get(EventHubsHeaders.SEQUENCE_NUMBER),
                message.getHeaders().get(EventHubsHeaders.OFFSET),
                message.getHeaders().get(EventHubsHeaders.ENQUEUED_TIME)
        );

        checkpointer.success()
                .doOnSuccess(success -> LOGGER.info("Message '{}' successfully checkpointed", message.getPayload()))
                .doOnError(error -> LOGGER.error("Exception found", error))
                .subscribe();
    };
}

@Bean
public Supplier<Message<String>> supply() {
    return () -> {
        LOGGER.info("Sending message, sequence " + i);
        return MessageBuilder.withPayload("Hello world, " + i++).build();
    };
}
----

===== Partitioning support
A `PartitionSupplier` with user-provided partition information will be created to configure the partition information about the message to be sent, the following is the process of obtaining different priorities of the partition ID and key:

image:https://user-images.githubusercontent.com/63028776/145347877-fa8afa90-ec28-4c0a-8277-63b9fdaa5d0f.png[]

===== Batch Consumer Support

Step 1. Fill the batch configuration options
[source,yaml]
----
spring:
  cloud:
    stream:
      function:
        definition: consume
      bindings:
        consume-in-0:
          destination: ${AZURE_EVENTHUB_NAME}
          group: ${AZURE_EVENTHUB_CONSUMER_GROUP}
          consumer:
            batch-mode: true
      eventhubs:
        bindings:
          consume-in-0:
            consumer:
              batch:
                max-batch-size: 10 # Required for batch-consumer mode
                max-wait-time: 1m # Optional, the default value is null
              checkpoint:
                mode: BATCH # or MANUAL as needed
----

Step2. Define supplier and consumer.

For checkpointing mode as `BATCH`, you can use below code to send messages and consume in batches.
[source,java]
----
@Bean
public Consumer<Message<List<String>>> consume() {
    return message -> {
            for (int i = 0; i < message.getPayload().size(); i++) {
                LOGGER.info("New message received: '{}', partition key: {}, sequence number: {}, offset: {}, enqueued time: {}",
                        message.getPayload().get(i),
                        ((List<Object>) message.getHeaders().get(EventHubsHeaders.BATCH_CONVERTED_PARTITION_KEY)).get(i),
                        ((List<Object>) message.getHeaders().get(EventHubsHeaders.BATCH_CONVERTED_SEQUENCE_NUMBER)).get(i),
                        ((List<Object>) message.getHeaders().get(EventHubsHeaders.BATCH_CONVERTED_OFFSET)).get(i),
                        ((List<Object>) message.getHeaders().get(EventHubsHeaders.BATCH_CONVERTED_ENQUEUED_TIME)).get(i));
            }

        };
}

@Bean
public Supplier<Message<String>> supply() {
    return () -> {
        LOGGER.info("Sending message, sequence " + i);
        return MessageBuilder.withPayload("\"test"+ i++ +"\"").build();
    };
}
----

For checkpointing mode as `MANUAL`, you can use below code to send messages and consume/checkpoint in batches.
[source,java]
----
@Bean
public Consumer<Message<List<String>>> consume() {
    return message -> {
        for (int i = 0; i < message.getPayload().size(); i++) {
            LOGGER.info("New message received: '{}', partition key: {}, sequence number: {}, offset: {}, enqueued time: {}",
                message.getPayload().get(i),
                ((List<Object>) message.getHeaders().get(EventHubHeaders.BATCH_CONVERTED_PARTITION_KEY)).get(i),
                ((List<Object>) message.getHeaders().get(EventHubHeaders.BATCH_CONVERTED_SEQUENCE_NUMBER)).get(i),
                ((List<Object>) message.getHeaders().get(EventHubHeaders.BATCH_CONVERTED_OFFSET)).get(i),
                ((List<Object>) message.getHeaders().get(EventHubHeaders.BATCH_CONVERTED_ENQUEUED_TIME)).get(i));
        }

        Checkpointer checkpointer = (Checkpointer) message.getHeaders().get(CHECKPOINTER);
        checkpointer.success()
                    .doOnSuccess(success -> LOGGER.info("Message '{}' successfully checkpointed", message.getPayload()))
                    .doOnError(error -> LOGGER.error("Exception found", error))
                    .subscribe();
    };
}

@Bean
public Supplier<Message<String>> supply() {
    return () -> {
        LOGGER.info("Sending message, sequence " + i);
        return MessageBuilder.withPayload("\"test"+ i++ +"\"").build();
    };
}
----

NOTE: In the batch-consuming mode, the default content type of Spring Cloud Stream binder is `application/json`, so make sure the message payload is aligned with the content type. For example, when using the default content type of `application/json` to receive messages with `String` payload, the payload should be JSON String, surrounded with double quotes for the original String text. While for `text/plain` content type, it can be a `String` object directly. For more details, please refer to the official doc of {content-type-negotiation}[Spring Cloud Stream Content Type Negotiation].

===== Error channels
- Consumer error channel

This channel is open by default, you can handle the error message in this way:
[source,java]
----
// Replace destination with spring.cloud.stream.bindings.input.destination
// Replace group with spring.cloud.stream.bindings.input.group
@ServiceActivator(inputChannel = "{destination}.{group}.errors")
public void consumerError(Message<?> message) {
    LOGGER.error("Handling customer ERROR: " + message);
}
----
- Producer error channel

This channel is not open by default. You need to add a configuration in your application.properties to enable it, like this:
[source,properties]
----
spring.cloud.stream.default.producer.errorChannelEnabled=true
----

You can handle the error message in this way:
[source,java]
----
// Replace destination with spring.cloud.stream.bindings.output.destination
@ServiceActivator(inputChannel = "{destination}.errors")
public void producerError(Message<?> message) {
    LOGGER.error("Handling Producer ERROR: " + message);
}
----

- Global default error channel

A global error channel called "errorChannel" is created by default Spring Integration, which allows users to subscribe many endpoints to it.

[source,java]
----
@ServiceActivator(inputChannel = "errorChannel")
public void producerError(Message<?> message) {
    LOGGER.error("Handling ERROR: " + message);
}
----

[#scs-eh-headers]
===== Event Hubs message headers
See the <<si-eh-headers, Event Hubs message headers>> for the basic message headers supported.

When the batch-consumer mode is enabled, the specific headers of batched messages are listed as below, which contains a list of values from each single Event Hubs event.

.Mapping between Batch Event Hubs Properties and Spring Headers
[cols="<,<,<,<", options="header"]
|===
|Event Hubs Event Properties | Spring Batch Message Header Constants | Type | Description

|Enqueued time
|com.azure.spring.messaging.eventhubs.support.EventHubsHeaders#BATCH_CONVERTED_ENQUEUED_TIME
|List of Instant
|List of the instant, in UTC, of when each event was enqueued in the Event Hub partition.

|Offset
|com.azure.spring.messaging.eventhubs.support.EventHubsHeaders#BATCH_CONVERTED_OFFSET
|List of Long
|List of the offset of each event when it was received from the associated Event Hub partition.

|Partition key
|com.azure.spring.messaging.AzureHeaders#BATCH_CONVERTED_PARTITION_KEY
|List of String
|List of the partition hashing key if it was set when originally publishing each event.

|Sequence number
|com.azure.spring.messaging.eventhubs.support.EventHubsHeaders#BATCH_CONVERTED_SEQUENCE_NUMBER
|List of Long
|List of the sequence number assigned to each event when it was enqueued in the associated Event Hub partition.

|System properties
|com.azure.spring.messaging.eventhubs.support.EventHubsHeaders#BATCH_CONVERTED_SYSTEM_PROPERTIES
|List of Map
|List of the system properties of each event.

|Application properties
|com.azure.spring.messaging.eventhubs.support.EventHubsHeaders#BATCH_CONVERTED_APPLICATION_PROPERTIES
|List of Map
|List of the applocation properties of each event, where all customized message headers or event properties are placed.
|===

NOTE: When publish messages, all the above batch headers if exist will be removed from the messages to send.

===== Multi Binder Support
Connection to mutiple Event Hubs namespaces is also supported by using multi binders.This sample takes connection string as example. Credentials of service priciple and MSI are also supported, users can set related properties in each binder's environment settings.

Step 1. To use multiple binders of EventHubs, we need to configure below properties in application.yml
[source,yaml]
----
spring:
  cloud:
    stream:
      function:
        definition: consume1;supply1;consume2;supply2
      bindings:
        consume1-in-0:
          destination: ${EVENTHUB_NAME_01}
          group: ${CONSUMER_GROUP_01}
        supply1-out-0:
          destination: ${THE_SAME_EVENTHUB_NAME_01_AS_ABOVE}
        consume2-in-0:
          binder: eventhub-2
          destination: ${EVENTHUB_NAME_02}
          group: ${CONSUMER_GROUP_02}
        supply2-out-0:
          binder: eventhub-2
          destination: ${THE_SAME_EVENTHUB_NAME_02_AS_ABOVE}
      binders:
        eventhub-1:
          type: eventhubs
          default-candidate: true
          environment:
            spring:
              cloud:
                azure:
                  eventhubs:
                    connection-string: ${EVENTHUB_NAMESPACE_01_CONNECTION_STRING}
                    processor:
                      checkpoint-store:
                        container-name: ${CHECKPOINT_CONTAINER_01}
                        account-name: ${CHECKPOINT_STORAGE_ACCOUNT}
                        account-key: ${CHECKPOINT_ACCESS_KEY}
        eventhub-2:
          type: eventhubs
          default-candidate: false
          environment:
            spring:
              cloud:
                azure:
                  eventhubs:
                    connection-string: ${EVENTHUB_NAMESPACE_02_CONNECTION_STRING}
                    processor:
                      checkpoint-store:
                        container-name: ${CHECKPOINT_CONTAINER_02}
                        account-name: ${CHECKPOINT_STORAGE_ACCOUNT}
                        account-key: ${CHECKPOINT_ACCESS_KEY}
      eventhubs:
        bindings:
          consume1-in-0:
            consumer:
              checkpoint:
                mode: MANUAL
          consume2-in-0:
            consumer:
              checkpoint:
                mode: MANUAL
      poller:
        initial-delay: 0
        fixed-delay: 1000
----
Step 2. we need define two suppliers and two consumers
[source,java]
----
@Bean
public Supplier<Message<String>> supply1() {
    return () -> {
        LOGGER.info("Sending message1, sequence1 " + i);
        return MessageBuilder.withPayload("Hello world1, " + i++).build();
    };
}

@Bean
public Supplier<Message<String>> supply2() {
    return () -> {
        LOGGER.info("Sending message2, sequence2 " + j);
        return MessageBuilder.withPayload("Hello world2, " + j++).build();
    };
}

@Bean
public Consumer<Message<String>> consume1() {
    return message -> {
        Checkpointer checkpointer = (Checkpointer) message.getHeaders().get(CHECKPOINTER);
        LOGGER.info("New message1 received: '{}'", message);
        checkpointer.success()
                .doOnSuccess(success -> LOGGER.info("Message1 '{}' successfully checkpointed", message))
                .doOnError(error -> LOGGER.error("Exception found", error))
                .subscribe();
    };
}

@Bean
public Consumer<Message<String>> consume2() {
    return message -> {
        Checkpointer checkpointer = (Checkpointer) message.getHeaders().get(CHECKPOINTER);
        LOGGER.info("New message2 received: '{}'", message);
        checkpointer.success()
                .doOnSuccess(success -> LOGGER.info("Message2 '{}' successfully checkpointed", message))
                .doOnError(error -> LOGGER.error("Exception found", error))
                .subscribe();
    };
}
----

===== Resource Provision
Event Hubs binder supports provisioning of event hub and consumer group, users could use below properties to enable provisioning.
[source,yaml]
----
spring:
  cloud:
    azure:
      credential:
        tenant-id: ${AZURE_TENANT_ID}
      profile:
        subscription-id: ${AZURE_SUBSCRIPTION_ID}
      eventhubs:
        resource:
          resource-group: ${AZURE_EVENTHUBS_RESOURECE_GROUP}
----

==== Samples

Please refer to link:https://github.com/Azure-Samples/azure-spring-boot-samples/tree/spring-cloud-azure_{project-version}/eventhubs/spring-cloud-azure-stream-binder-eventhubs[azure-spring-boot-samples] for more details.

=== Spring Cloud Stream Binder for Azure Service Bus

==== Key concepts
The Spring Cloud Stream Binder for Azure Service Bus provides the binding implementation for the Spring Cloud Stream Framework.
This implementation uses Spring Integration Service Bus Channel Adapters at its foundation.

===== Scheduled Message
This binder supports submitting messages to a topic for delayed processing. Users can send scheduled messages with header `x-delay`
expressing in milliseconds a delay time for the message. The message will be delivered to the respective topics after `x-delay` milliseconds.

===== Consumer Group

Service Bus Topic provides similar support of consumer group as Apache Kafka, but with slight different logic.
This binder relies on `Subscription` of a topic to act as a consumer group.

==== Dependency Setup

[source,xml]
----
<dependency>
	<groupId>com.azure.spring</groupId>
	<artifactId>spring-cloud-azure-stream-binder-servicebus</artifactId>
</dependency>
----
Alternatively, you can also use the Spring Cloud Azure Stream Service Bus Starter, as shown in the following example for Maven:

[source,xml]
----
<dependency>
	<groupId>com.azure.spring</groupId>
	<artifactId>spring-cloud-azure-starter-stream-servicebus</artifactId>
</dependency>
----

==== Configuration
The binder provides the following 2 parts of configuration options:

[#servicebus-connection-configration]
===== Connection Configuration Properties
These properties are exposed via `com.azure.spring.cloud.autoconfigure.implementation.servicebus.properties.AzureServiceBusProperties`.

NOTE: If you choose to use a security principal to authenticate and authorize with Azure Active Directory for accessing an Azure resource, please refer to link:index.html#authorize-access-with-azure-active-directory[Authorize access with Azure AD] to make sure the security principal has been granted the sufficient permission to access the Azure resource.

.Connection configurable properties of spring-cloud-azure-stream-binder-servicebus
[cols="<,<,<", options="header"]
|===
|Property | Type |Description

|*spring.cloud.azure.servicebus*.enabled
| boolean
| Whether an Azure Service Bus is enabled.

|*spring.cloud.azure.servicebus*.connection-string
| String
| Service Bus Namespace connection string value.

|*spring.cloud.azure.servicebus*.namespace
| String
| Service Bus Namespace value, which is the prefix of the FQDN. A FQDN should be composed of <NamespaceName>.<DomainName>

|*spring.cloud.azure.servicebus*.domain-name
| String
| Domain name of an Azure Service Bus Namespace value.

|===

TIP: Common Azure Service SDK configuration options are configurable for the Spring Cloud Azure Stream Service Bus binder as well. The supported configuration options are introduced in link:configuration.html[the Configuration page], and could be configured with either the unified prefix `spring.cloud.azure.` or the prefix of `spring.cloud.azure.servicebus.`.

===== Azure Service Bus Binding Configuration Properties
Below options are divided into four sections: Consumer Properties, Advanced Consumer
Configurations, Producer Properties and Advanced Producer Configurations.

====== Consumer Properties

.Consumer configurable properties of spring-cloud-azure-stream-binder-servicebus
[cols="<,<,<,<", options="header"]
|===
|Property | Type |Default |Description

|*spring.cloud.stream.servicebus.bindings.<binding-name>.consumer*.requeue-rejected
|boolean
|false
|If the failed messages are routed to the DLQ.

|*spring.cloud.stream.servicebus.bindings.<binding-name>.consumer*.checkpoint-mode
| CheckpointMode
| RECORD
| The checkpoint mode of checkpointing message. The supported modes are `MANUAL` and `RECORD`.

|*spring.cloud.stream.servicebus.bindings.<binding-name>.consumer*.max-concurrent-calls
| Integer
| 1
| Max concurrent messages that the Service Bus processor client should process.

|*spring.cloud.stream.servicebus.bindings.<binding-name>.consumer*.max-concurrent-sessions
|Integer
|null
| Maximum number of concurrent sessions to process at any given time.

|*spring.cloud.stream.servicebus.bindings.<binding-name>.consumer*.session-enabled
| Boolean
| null
| Whether session is enabled.

|*spring.cloud.stream.servicebus.bindings.<binding-name>.consumer*.prefetch-count
| Integer
| 0
| The prefetch count of the Service Bus processor client.

|*spring.cloud.stream.servicebus.bindings.<binding-name>.consumer*.sub-queue
| SubQueue
| none
| The type of the sub queue to connect to.

|*spring.cloud.stream.servicebus.bindings.<binding-name>.consumer*.max-auto-lock-renew-duration
| Duration
| 5m
| The amount of time to continue auto-renewing the lock.

|*spring.cloud.stream.servicebus.bindings.<binding-name>.consumer*.receive-mode
| ServiceBusReceiveMode
| peek_lock
| The receive mode of the Service Bus processor client.

|===

====== Advanced Consumer Configuration
The above <<servicebus-connection-configration, connection>> and <<Configuration.adoc#configuration, common Azure SDK client>> configuration are supported to be customized for each binder consumer, which can be configured with the prefix `spring.cloud.stream.servicebus.bindings.<binding-name>.consumer.`.

====== Producer Properties
.Producer configurable properties of spring-cloud-azure-stream-binder-servicebus
[cols="<,<,<,<", options="header"]
|===
|Property | Type | Default |Description

|*spring.cloud.stream.servicebus.bindings.<binding-name>.producer*.sync |boolean |false | Switch flag
for sync of producer.
|*spring.cloud.stream.servicebus.bindings.<binding-name>.producer*.send-timeout |long |10000 | Timeout
value for sending of producer.
|*spring.cloud.stream.servicebus.bindings.<binding-name>.producer*.entity-type |ServiceBusEntityType |null | Service Bus entity type of the producer, required for the binding producer.
|===

IMPORTANT: When using the binding producer, property of `spring.cloud.stream.servicebus.bindings.<binding-name>.producer.entity-type` is required to be configured.

====== Advanced Producer Configuration
The above <<servicebus-connection-configration, connection>> and <<Configuration.adoc#configuration, common Azure SDK client>> configuration are supported to be customized for each binder producer, which can be configured with the prefix `spring.cloud.stream.servicebus.bindings.<binding-name>.producer.`.

==== Basic Usage
===== Sending and receiving messages from/to Service Bus
Step 1. Fill the configuration options with credential information.

- For credentials as connection string, configure below properties in application.yml:
[source,yaml]
----
spring:
  cloud:
    azure:
      servicebus:
        connection-string: ${SERVICEBUS_NAMESPACE_CONNECTION_STRING}
    stream:
      function:
        definition: consume;supply
      bindings:
        consume-in-0:
          destination: ${SERVICEBUS_ENTITY_NAME}
          # If you use Service Bus Topic, please add below configuration
          # group: ${SUBSCRIPTION_NAME}
        supply-out-0:
          destination: ${SERVICEBUS_ENTITY_NAME_SAME_AS_ABOVE}
      servicebus:
        bindings:
          consume-in-0:
            consumer:
              checkpoint-mode: MANUAL
          supply-out-0:
            producer:
              entity-type: queue # set as "topic" if you use Service Bus Topic
----

- For credentials as service principal, configure below properties in application.yml:
[source,yaml]
----
spring:
  cloud:
    azure:
      credential:
        client-id: ${CLIENT_ID}
        client-secret: ${CLIENT_SECRET}
      profile:
        tenant-id: ${TENANT_ID}
      servicebus:
        namespace: ${SERVICEBUS_NAMESPACE}
    stream:
      function:
        definition: consume;supply
      bindings:
        consume-in-0:
          destination: ${SERVICEBUS_ENTITY_NAME}
          # If you use Service Bus Topic, please add below configuration
          # group: ${SUBSCRIPTION_NAME}
        supply-out-0:
          destination: ${SERVICEBUS_ENTITY_NAME_SAME_AS_ABOVE}
      servicebus:
        bindings:
          consume-in-0:
            consumer:
              checkpoint-mode: MANUAL
          supply-out-0:
            producer:
              entity-type: queue # set as "topic" if you use Service Bus Topic
----

- For credentials as MSI, configure below properties in application.yml:
[source, yaml]
----
spring:
  cloud:
    azure:
      credential:
        managed-identity-client-id: ${MANAGED_IDENTITY_CLIENT_ID}
      servicebus:
        namespace: ${SERVICEBUS_NAMESPACE}
    stream:
      function:
        definition: consume;supply
      bindings:
        consume-in-0:
          destination: ${SERVICEBUS_ENTITY_NAME}
          # If you use Service Bus Topic, please add below configuration
          # group: ${SUBSCRIPTION_NAME}
        supply-out-0:
          destination: ${SERVICEBUS_ENTITY_NAME_SAME_AS_ABOVE}
      servicebus:
        bindings:
          consume-in-0:
            consumer:
              checkpoint-mode: MANUAL
          supply-out-0:
            producer:
              entity-type: queue # set as "topic" if you use Service Bus Topic

----

Step 2. Define supplier and consumer.
[source,java]
----
@Bean
public Consumer<Message<String>> consume() {
    return message -> {
        Checkpointer checkpointer = (Checkpointer) message.getHeaders().get(CHECKPOINTER);
        LOGGER.info("New message received: '{}', partition key: {}, sequence number: {}, offset: {}, enqueued time: {}",
                message.getPayload(),
                message.getHeaders().get(EventHubsHeaders.PARTITION_KEY),
                message.getHeaders().get(EventHubsHeaders.SEQUENCE_NUMBER),
                message.getHeaders().get(EventHubsHeaders.OFFSET),
                message.getHeaders().get(EventHubsHeaders.ENQUEUED_TIME)
        );

        checkpointer.success()
                .doOnSuccess(success -> LOGGER.info("Message '{}' successfully checkpointed", message.getPayload()))
                .doOnError(error -> LOGGER.error("Exception found", error))
                .subscribe();
    };
}

@Bean
public Supplier<Message<String>> supply() {
    return () -> {
        LOGGER.info("Sending message, sequence " + i);
        return MessageBuilder.withPayload("Hello world, " + i++).build();
    };
}
----

===== Partition key support

The binder supports link:https://docs.microsoft.com/azure/service-bus-messaging/service-bus-partitioning[Service Bus partitioning] by allowing setting partition key and session id in the message header. This section introduces how to set partition key for messages.

Spring Cloud Stream provides a partition key SpEL expression property `spring.cloud.stream.bindings.<binding-name>.producer.partition-key-expression`. For example, setting this properts as `&quot;&#39;partitionKey-&#39; + headers[&lt;message-header-key&gt;]&quot;` and add a header called <message-header-key>. Spring Cloud Stream will use the value for this header when evaluating the above expression to assign a partition key. Here is an example producer code:

[source,java]
----
@Bean
public Supplier<Message<String>> generate() {
    return () -> {
        String value = “random payload”;
    	return MessageBuilder.withPayload(value)
            .setHeader("<message-header-key>", value.length() % 4)
            .build();
    };
}
----

===== Session support

The binder supports link:https://docs.microsoft.com/azure/service-bus-messaging/message-sessions[message sessions] of Service Bus. Session id of a message could be set via the message header.

[source,java]
----
@Bean
public Supplier<Message<String>> generate() {
    return () -> {
        String value = “random payload”;
    	return MessageBuilder.withPayload(value)
            .setHeader(ServiceBusMessageHeaders.SESSION_ID, "Customize session id")
            .build();
    };
}
----

NOTE: According to link:https://docs.microsoft.com/azure/service-bus-messaging/service-bus-partitioning[Service Bus partitioning], session id has higher priority than partition key. So when both of `ServiceBusMessageHeaders#SESSION_ID` and `ServiceBusMessageHeaders#PARTITION_KEY` (or `AzureHeaders#PARTITION_KEY`) headers are set,
the value of the session id will eventually be used to overwrite the value of the partition key.

===== Error channels
- Consumer error channel

This channel is open by default, and a default consumer error channel handler is used to send failed messages to the dead-letter queue when `spring.cloud.stream.servicebus.bindings.<binding-name>.consumer.requeue-rejected` is enabled, otherwise the failed messages will be abandoned.

To customize the consumer error channel handler, you can register you own error handler to the related consumer error channel in this way:
[source,java]
----
// Replace destination with spring.cloud.stream.bindings.input.destination
// Replace group with spring.cloud.stream.bindings.input.group
@ServiceActivator(inputChannel = "{destination}.{group}.errors")
public void consumerError(Message<?> message) {
    LOGGER.error("Handling customer ERROR: " + message);
}
----

- Producer error channel

This channel is not open by default. You need to add a configuration in your application.properties to enable it, like this:
[source,properties]
----
spring.cloud.stream.default.producer.errorChannelEnabled=true
----

You can handle the error message in this way:
[source,java]
----
// Replace destination with spring.cloud.stream.bindings.output.destination
@ServiceActivator(inputChannel = "{destination}.errors")
public void producerError(Message<?> message) {
    LOGGER.error("Handling Producer ERROR: " + message);
}
----

- Global default error channel

A global error channel called "errorChannel" is created by default Spring Integration, which allows users to subscribe many endpoints to it.

[source,java]
----
@ServiceActivator(inputChannel = "errorChannel")
public void producerError(Message<?> message) {
    LOGGER.error("Handling ERROR: " + message);
}
----

[#scs-sb-headers]
===== Service Bus message headers

See the <<si-sb-headers, Service Bus message headers>> for the basic message headers supported.

NOTE: When setting the partiton key, the priority of message header is higher than Spring Cloud Stream property. So `spring.cloud.stream.bindings.<binding-name>.producer.partition-key-expression` will take effect only when none of the headers of `ServiceBusMessageHeaders#SESSION_ID`, `ServiceBusMessageHeaders#PARTITION_KEY`, `AzureHeaders#PARTITION_KEY` is configured.

===== Multi Binder Support
Connection to mutiple Service Bus namespaces is also supported by using multi binders.This sample takes connection string as example. Credentials of service priciple and MSI are also supported, users can set related properties in each binder's environment settings.

Step 1. To use multiple binders of ServiceBus, we need to configure below properties in application.yml
[source,yaml]
----
spring:
  cloud:
    stream:
      function:
        definition: consume1;supply1;consume2;supply2
      bindings:
        consume1-in-0:
          destination: ${SERVICEBUS_TOPIC_NAME}
          group: ${SUBSCRIPTION_NAME}
        supply1-out-0:
          destination: ${SERVICEBUS_TOPIC_NAME_SAME_AS_ABOVE}
        consume2-in-0:
          binder: servicebus-2
          destination: ${SERVICEBUS_QUEUE_NAME}
        supply2-out-0:
          binder: servicebus-2
          destination: ${SERVICEBUS_QUEUE_NAME_SAME_AS_ABOVE}
      binders:
        servicebus-1:
          type: servicebus
          default-candidate: true
          environment:
            spring:
              cloud:
                azure:
                  servicebus:
                    connection-string: ${SERVICEBUS_NAMESPACE_01_CONNECTION_STRING}
        servicebus-2:
          type: servicebus
          default-candidate: false
          environment:
            spring:
              cloud:
                azure:
                  servicebus:
                    connection-string: ${SERVICEBUS_NAMESPACE_02_CONNECTION_STRING}
      servicebus:
        bindings:
          consume1-in-0:
            consumer:
              checkpoint-mode: MANUAL
          supply1-out-0:
            producer:
              entity-type: topic
          consume2-in-0:
            consumer:
              checkpoint-mode: MANUAL
          supply2-out-0:
            producer:
              entity-type: queue
      poller:
        initial-delay: 0
        fixed-delay: 1000
----
Step 2. we need define two suppliers and two consumers
[source,java]
----
@Bean
public Supplier<Message<String>> supply1() {
    return () -> {
        LOGGER.info("Sending message1, sequence1 " + i);
        return MessageBuilder.withPayload("Hello world1, " + i++).build();
    };
}

@Bean
public Supplier<Message<String>> supply2() {
    return () -> {
        LOGGER.info("Sending message2, sequence2 " + j);
        return MessageBuilder.withPayload("Hello world2, " + j++).build();
    };
}

@Bean
public Consumer<Message<String>> consume1() {
    return message -> {
        Checkpointer checkpointer = (Checkpointer) message.getHeaders().get(CHECKPOINTER);
        LOGGER.info("New message1 received: '{}'", message);
        checkpointer.success()
                .doOnSuccess(s -> LOGGER.info("Message '{}' successfully checkpointed", message.getPayload()))
                .doOnError(e -> LOGGER.error("Error found", e))
                .subscribe();
    };
}

@Bean
public Consumer<Message<String>> consume2() {
    return message -> {
        Checkpointer checkpointer = (Checkpointer) message.getHeaders().get(CHECKPOINTER);
        LOGGER.info("New message2 received: '{}'", message);
        checkpointer.success()
                .doOnSuccess(s -> LOGGER.info("Message '{}' successfully checkpointed", message.getPayload()))
                .doOnError(e -> LOGGER.error("Error found", e))
                .subscribe();
    };

}
----

===== Resource Provision
Service bus binder supports provisioning of queue, topic and subscription, users could use below properties to enable provisioning.
[source,yaml]
----
spring:
  cloud:
    azure:
      credential:
        tenant-id: ${AZURE_TENANT_ID}
      profile:
        subscription-id: ${AZURE_SUBSCRIPTION_ID}
      servicebus:
        resource:
          resource-group: ${AZURE_SERVICEBUS_RESOURECE_GROUP}
    stream:
      servicebus:
        bindings:
          <binding-name>:
            consumer:
              entity-type: ${SERVICEBUS_CONSUMER_ENTITY_TYPE}
----

==== Samples

Please refer to link:https://github.com/Azure-Samples/azure-spring-boot-samples/tree/spring-cloud-azure_{project-version}/servicebus/spring-cloud-azure-stream-binder-servicebus[azure-spring-boot-samples] for more details.
